{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN3eeiF9V3MTTjr5NQra7Pd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bhanuchaddha/The-Ai-Handbook/blob/main/4-ai-agents/customer_care_support/Multi_Agent_Customer_Care_Representative_With_CrewAI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this lesson, you will learn about the six key elements which help make Agents perform even better:\n",
        "\n",
        "* Role Playing\n",
        "* Focus\n",
        "Tools\n",
        "Cooperation\n",
        "Guardrails\n",
        "Memory"
      ],
      "metadata": {
        "id": "qqlm_0UfmCKC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "By not setting allow_delegation=False, allow_delegation takes its default value of being True.\n",
        "This means the agent can delegate its work to another agent which is better suited to do a particular task.\n",
        "\n",
        "Role Playing: Both agents have been given a role, goal and backstory.\n",
        "Focus: Both agents have been prompted to get into the character of the roles they are playing.\n",
        "Cooperation: Support Quality Assurance Agent can delegate work back to the Support Agent, allowing for these agents to work together.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "### Possible Custom Tools\n",
        "- Load customer data\n",
        "- Tap into previous conversations\n",
        "- Load data from a CRM\n",
        "- Checking existing bug reports\n",
        "- Checking existing feature requests\n",
        "- Checking ongoing tickets\n",
        "- ... and more\n",
        "\n",
        "\n",
        "\n",
        "- Some ways of using CrewAI tools.\n",
        "\n",
        "```Python\n",
        "search_tool = SerperDevTool()\n",
        "scrape_tool = ScrapeWebsiteTool()\n",
        "```"
      ],
      "metadata": {
        "id": "-ga1uy3XqTBU"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3Sl9Ymk6qSyM"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install crewai crewai-tools\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zvtvWiBhmRa-",
        "outputId": "f3ec83fc-b6a2-4aed-c6fd-a7615790bbad"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting crewai\n",
            "  Downloading crewai-0.86.0-py3-none-any.whl.metadata (19 kB)\n",
            "Collecting crewai-tools\n",
            "  Downloading crewai_tools-0.17.0-py3-none-any.whl.metadata (4.9 kB)\n",
            "Collecting appdirs>=1.4.4 (from crewai)\n",
            "  Downloading appdirs-1.4.4-py2.py3-none-any.whl.metadata (9.0 kB)\n",
            "Collecting auth0-python>=4.7.1 (from crewai)\n",
            "  Downloading auth0_python-4.7.2-py3-none-any.whl.metadata (8.9 kB)\n",
            "Collecting chromadb>=0.5.18 (from crewai)\n",
            "  Downloading chromadb-0.5.23-py3-none-any.whl.metadata (6.8 kB)\n",
            "Requirement already satisfied: click>=8.1.7 in /usr/local/lib/python3.10/dist-packages (from crewai) (8.1.7)\n",
            "Collecting instructor>=1.3.3 (from crewai)\n",
            "  Downloading instructor-1.7.0-py3-none-any.whl.metadata (17 kB)\n",
            "Collecting json-repair>=0.25.2 (from crewai)\n",
            "  Downloading json_repair-0.30.3-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting jsonref>=1.1.0 (from crewai)\n",
            "  Downloading jsonref-1.1.0-py3-none-any.whl.metadata (2.7 kB)\n",
            "Collecting litellm>=1.44.22 (from crewai)\n",
            "  Downloading litellm-1.54.0-py3-none-any.whl.metadata (33 kB)\n",
            "Requirement already satisfied: openai>=1.13.3 in /usr/local/lib/python3.10/dist-packages (from crewai) (1.54.5)\n",
            "Requirement already satisfied: openpyxl>=3.1.5 in /usr/local/lib/python3.10/dist-packages (from crewai) (3.1.5)\n",
            "Requirement already satisfied: opentelemetry-api>=1.22.0 in /usr/local/lib/python3.10/dist-packages (from crewai) (1.28.2)\n",
            "Collecting opentelemetry-exporter-otlp-proto-http>=1.22.0 (from crewai)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_http-1.28.2-py3-none-any.whl.metadata (2.2 kB)\n",
            "Requirement already satisfied: opentelemetry-sdk>=1.22.0 in /usr/local/lib/python3.10/dist-packages (from crewai) (1.28.2)\n",
            "Collecting pdfplumber>=0.11.4 (from crewai)\n",
            "  Downloading pdfplumber-0.11.4-py3-none-any.whl.metadata (41 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.0/42.0 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic>=2.4.2 in /usr/local/lib/python3.10/dist-packages (from crewai) (2.10.3)\n",
            "Collecting python-dotenv>=1.0.0 (from crewai)\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Collecting pyvis>=0.3.2 (from crewai)\n",
            "  Downloading pyvis-0.3.2-py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: regex>=2024.9.11 in /usr/local/lib/python3.10/dist-packages (from crewai) (2024.9.11)\n",
            "Collecting tomli-w>=1.1.0 (from crewai)\n",
            "  Downloading tomli_w-1.1.0-py3-none-any.whl.metadata (5.7 kB)\n",
            "Requirement already satisfied: tomli>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from crewai) (2.2.1)\n",
            "Collecting uv>=0.4.25 (from crewai)\n",
            "  Downloading uv-0.5.7-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
            "Requirement already satisfied: beautifulsoup4>=4.12.3 in /usr/local/lib/python3.10/dist-packages (from crewai-tools) (4.12.3)\n",
            "Collecting docker>=7.1.0 (from crewai-tools)\n",
            "  Downloading docker-7.1.0-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting docx2txt>=0.8 (from crewai-tools)\n",
            "  Downloading docx2txt-0.8.tar.gz (2.8 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting embedchain>=0.1.114 (from crewai-tools)\n",
            "  Downloading embedchain-0.1.125-py3-none-any.whl.metadata (9.3 kB)\n",
            "Collecting lancedb>=0.5.4 (from crewai-tools)\n",
            "  Downloading lancedb-0.17.0-cp39-abi3-manylinux_2_28_x86_64.whl.metadata (4.7 kB)\n",
            "Collecting pyright>=1.1.350 (from crewai-tools)\n",
            "  Downloading pyright-1.1.390-py3-none-any.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: pytest>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from crewai-tools) (8.3.4)\n",
            "Collecting pytube>=15.0.0 (from crewai-tools)\n",
            "  Downloading pytube-15.0.0-py3-none-any.whl.metadata (5.0 kB)\n",
            "Requirement already satisfied: requests>=2.31.0 in /usr/local/lib/python3.10/dist-packages (from crewai-tools) (2.32.3)\n",
            "Collecting selenium>=4.18.1 (from crewai-tools)\n",
            "  Downloading selenium-4.27.1-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.5 in /usr/local/lib/python3.10/dist-packages (from auth0-python>=4.7.1->crewai) (3.11.9)\n",
            "Requirement already satisfied: cryptography<44.0.0,>=43.0.1 in /usr/local/lib/python3.10/dist-packages (from auth0-python>=4.7.1->crewai) (43.0.3)\n",
            "Requirement already satisfied: pyjwt<3.0.0,>=2.8.0 in /usr/local/lib/python3.10/dist-packages (from auth0-python>=4.7.1->crewai) (2.10.1)\n",
            "Requirement already satisfied: urllib3<3.0.0,>=2.0.7 in /usr/local/lib/python3.10/dist-packages (from auth0-python>=4.7.1->crewai) (2.2.3)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4>=4.12.3->crewai-tools) (2.6)\n",
            "Collecting build>=1.0.3 (from chromadb>=0.5.18->crewai)\n",
            "  Downloading build-1.2.2.post1-py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting chroma-hnswlib==0.7.6 (from chromadb>=0.5.18->crewai)\n",
            "  Downloading chroma_hnswlib-0.7.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (252 bytes)\n",
            "Collecting fastapi>=0.95.2 (from chromadb>=0.5.18->crewai)\n",
            "  Downloading fastapi-0.115.6-py3-none-any.whl.metadata (27 kB)\n",
            "Collecting uvicorn>=0.18.3 (from uvicorn[standard]>=0.18.3->chromadb>=0.5.18->crewai)\n",
            "  Downloading uvicorn-0.32.1-py3-none-any.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: numpy>=1.22.5 in /usr/local/lib/python3.10/dist-packages (from chromadb>=0.5.18->crewai) (1.26.4)\n",
            "Collecting posthog>=2.4.0 (from chromadb>=0.5.18->crewai)\n",
            "  Downloading posthog-3.7.4-py2.py3-none-any.whl.metadata (2.0 kB)\n",
            "Requirement already satisfied: typing_extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from chromadb>=0.5.18->crewai) (4.12.2)\n",
            "Collecting onnxruntime>=1.14.1 (from chromadb>=0.5.18->crewai)\n",
            "  Downloading onnxruntime-1.20.1-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.5 kB)\n",
            "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb>=0.5.18->crewai)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.28.2-py3-none-any.whl.metadata (2.2 kB)\n",
            "Collecting opentelemetry-instrumentation-fastapi>=0.41b0 (from chromadb>=0.5.18->crewai)\n",
            "  Downloading opentelemetry_instrumentation_fastapi-0.49b2-py3-none-any.whl.metadata (2.1 kB)\n",
            "Requirement already satisfied: tokenizers<=0.20.3,>=0.13.2 in /usr/local/lib/python3.10/dist-packages (from chromadb>=0.5.18->crewai) (0.20.3)\n",
            "Collecting pypika>=0.48.9 (from chromadb>=0.5.18->crewai)\n",
            "  Downloading PyPika-0.48.9.tar.gz (67 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.10/dist-packages (from chromadb>=0.5.18->crewai) (4.66.6)\n",
            "Collecting overrides>=7.3.1 (from chromadb>=0.5.18->crewai)\n",
            "  Downloading overrides-7.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.10/dist-packages (from chromadb>=0.5.18->crewai) (6.4.5)\n",
            "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.10/dist-packages (from chromadb>=0.5.18->crewai) (1.68.1)\n",
            "Collecting bcrypt>=4.0.1 (from chromadb>=0.5.18->crewai)\n",
            "  Downloading bcrypt-4.2.1-cp39-abi3-manylinux_2_28_x86_64.whl.metadata (9.8 kB)\n",
            "Requirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from chromadb>=0.5.18->crewai) (0.15.0)\n",
            "Collecting kubernetes>=28.1.0 (from chromadb>=0.5.18->crewai)\n",
            "  Downloading kubernetes-31.0.0-py2.py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: tenacity>=8.2.3 in /usr/local/lib/python3.10/dist-packages (from chromadb>=0.5.18->crewai) (9.0.0)\n",
            "Requirement already satisfied: PyYAML>=6.0.0 in /usr/local/lib/python3.10/dist-packages (from chromadb>=0.5.18->crewai) (6.0.2)\n",
            "Collecting mmh3>=4.0.1 (from chromadb>=0.5.18->crewai)\n",
            "  Downloading mmh3-5.0.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (14 kB)\n",
            "Requirement already satisfied: orjson>=3.9.12 in /usr/local/lib/python3.10/dist-packages (from chromadb>=0.5.18->crewai) (3.10.12)\n",
            "Requirement already satisfied: httpx>=0.27.0 in /usr/local/lib/python3.10/dist-packages (from chromadb>=0.5.18->crewai) (0.28.0)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from chromadb>=0.5.18->crewai) (13.9.4)\n",
            "Collecting alembic<2.0.0,>=1.13.1 (from embedchain>=0.1.114->crewai-tools)\n",
            "  Downloading alembic-1.14.0-py3-none-any.whl.metadata (7.4 kB)\n",
            "Collecting cohere<6.0,>=5.3 (from embedchain>=0.1.114->crewai-tools)\n",
            "  Downloading cohere-5.13.3-py3-none-any.whl.metadata (3.5 kB)\n",
            "Requirement already satisfied: google-cloud-aiplatform<2.0.0,>=1.26.1 in /usr/local/lib/python3.10/dist-packages (from embedchain>=0.1.114->crewai-tools) (1.73.0)\n",
            "Collecting gptcache<0.2.0,>=0.1.43 (from embedchain>=0.1.114->crewai-tools)\n",
            "  Downloading gptcache-0.1.44-py3-none-any.whl.metadata (24 kB)\n",
            "Requirement already satisfied: langchain<0.4.0,>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from embedchain>=0.1.114->crewai-tools) (0.3.9)\n",
            "Collecting langchain-cohere<0.4.0,>=0.3.0 (from embedchain>=0.1.114->crewai-tools)\n",
            "  Downloading langchain_cohere-0.3.3-py3-none-any.whl.metadata (6.7 kB)\n",
            "Collecting langchain-community<0.4.0,>=0.3.1 (from embedchain>=0.1.114->crewai-tools)\n",
            "  Downloading langchain_community-0.3.10-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting langchain-openai<0.3.0,>=0.2.1 (from embedchain>=0.1.114->crewai-tools)\n",
            "  Downloading langchain_openai-0.2.11-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /usr/local/lib/python3.10/dist-packages (from embedchain>=0.1.114->crewai-tools) (0.1.147)\n",
            "Collecting mem0ai<0.2.0,>=0.1.29 (from embedchain>=0.1.114->crewai-tools)\n",
            "  Downloading mem0ai-0.1.34-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting pypdf<6.0.0,>=5.0.0 (from embedchain>=0.1.114->crewai-tools)\n",
            "  Downloading pypdf-5.1.0-py3-none-any.whl.metadata (7.2 kB)\n",
            "Collecting pysbd<0.4.0,>=0.3.4 (from embedchain>=0.1.114->crewai-tools)\n",
            "  Downloading pysbd-0.3.4-py3-none-any.whl.metadata (6.1 kB)\n",
            "Collecting schema<0.8.0,>=0.7.5 (from embedchain>=0.1.114->crewai-tools)\n",
            "  Downloading schema-0.7.7-py2.py3-none-any.whl.metadata (34 kB)\n",
            "Requirement already satisfied: sqlalchemy<3.0.0,>=2.0.27 in /usr/local/lib/python3.10/dist-packages (from embedchain>=0.1.114->crewai-tools) (2.0.36)\n",
            "Collecting tiktoken<0.8.0,>=0.7.0 (from embedchain>=0.1.114->crewai-tools)\n",
            "  Downloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: docstring-parser<0.17,>=0.16 in /usr/local/lib/python3.10/dist-packages (from instructor>=1.3.3->crewai) (0.16)\n",
            "Requirement already satisfied: jinja2<4.0.0,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from instructor>=1.3.3->crewai) (3.1.4)\n",
            "Collecting jiter<0.7,>=0.6.1 (from instructor>=1.3.3->crewai)\n",
            "  Downloading jiter-0.6.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.2 kB)\n",
            "Requirement already satisfied: pydantic-core<3.0.0,>=2.18.0 in /usr/local/lib/python3.10/dist-packages (from instructor>=1.3.3->crewai) (2.27.1)\n",
            "Collecting deprecation (from lancedb>=0.5.4->crewai-tools)\n",
            "  Downloading deprecation-2.1.0-py2.py3-none-any.whl.metadata (4.6 kB)\n",
            "Collecting pylance==0.20.0 (from lancedb>=0.5.4->crewai-tools)\n",
            "  Downloading pylance-0.20.0-cp39-abi3-manylinux_2_28_x86_64.whl.metadata (7.4 kB)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from lancedb>=0.5.4->crewai-tools) (24.2)\n",
            "Requirement already satisfied: pyarrow>=14 in /usr/local/lib/python3.10/dist-packages (from pylance==0.20.0->lancedb>=0.5.4->crewai-tools) (17.0.0)\n",
            "Collecting httpx>=0.27.0 (from chromadb>=0.5.18->crewai)\n",
            "  Downloading httpx-0.27.2-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: importlib-metadata>=6.8.0 in /usr/local/lib/python3.10/dist-packages (from litellm>=1.44.22->crewai) (8.5.0)\n",
            "Requirement already satisfied: jsonschema<5.0.0,>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from litellm>=1.44.22->crewai) (4.23.0)\n",
            "Collecting openai>=1.13.3 (from crewai)\n",
            "  Downloading openai-1.57.0-py3-none-any.whl.metadata (24 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai>=1.13.3->crewai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from openai>=1.13.3->crewai) (1.9.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai>=1.13.3->crewai) (1.3.1)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.10/dist-packages (from openpyxl>=3.1.5->crewai) (2.0.0)\n",
            "Requirement already satisfied: deprecated>=1.2.6 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-api>=1.22.0->crewai) (1.2.15)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.52 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-exporter-otlp-proto-http>=1.22.0->crewai) (1.66.0)\n",
            "Collecting opentelemetry-exporter-otlp-proto-common==1.28.2 (from opentelemetry-exporter-otlp-proto-http>=1.22.0->crewai)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_common-1.28.2-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting opentelemetry-proto==1.28.2 (from opentelemetry-exporter-otlp-proto-http>=1.22.0->crewai)\n",
            "  Downloading opentelemetry_proto-1.28.2-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting protobuf<6.0,>=5.0 (from opentelemetry-proto==1.28.2->opentelemetry-exporter-otlp-proto-http>=1.22.0->crewai)\n",
            "  Downloading protobuf-5.29.1-cp38-abi3-manylinux2014_x86_64.whl.metadata (592 bytes)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions==0.49b2 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-sdk>=1.22.0->crewai) (0.49b2)\n",
            "Collecting pdfminer.six==20231228 (from pdfplumber>=0.11.4->crewai)\n",
            "  Downloading pdfminer.six-20231228-py3-none-any.whl.metadata (4.2 kB)\n",
            "Requirement already satisfied: Pillow>=9.1 in /usr/local/lib/python3.10/dist-packages (from pdfplumber>=0.11.4->crewai) (11.0.0)\n",
            "Collecting pypdfium2>=4.18.0 (from pdfplumber>=0.11.4->crewai)\n",
            "  Downloading pypdfium2-4.30.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (48 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.5/48.5 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from pdfminer.six==20231228->pdfplumber>=0.11.4->crewai) (3.4.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.4.2->crewai) (0.7.0)\n",
            "Collecting nodeenv>=1.6.0 (from pyright>=1.1.350->crewai-tools)\n",
            "  Downloading nodeenv-1.9.1-py2.py3-none-any.whl.metadata (21 kB)\n",
            "Requirement already satisfied: exceptiongroup>=1.0.0rc8 in /usr/local/lib/python3.10/dist-packages (from pytest>=8.0.0->crewai-tools) (1.2.2)\n",
            "Requirement already satisfied: iniconfig in /usr/local/lib/python3.10/dist-packages (from pytest>=8.0.0->crewai-tools) (2.0.0)\n",
            "Requirement already satisfied: pluggy<2,>=1.5 in /usr/local/lib/python3.10/dist-packages (from pytest>=8.0.0->crewai-tools) (1.5.0)\n",
            "Requirement already satisfied: ipython>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from pyvis>=0.3.2->crewai) (7.34.0)\n",
            "Requirement already satisfied: jsonpickle>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from pyvis>=0.3.2->crewai) (4.0.0)\n",
            "Requirement already satisfied: networkx>=1.11 in /usr/local/lib/python3.10/dist-packages (from pyvis>=0.3.2->crewai) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->crewai-tools) (3.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->crewai-tools) (2024.8.30)\n",
            "Collecting trio~=0.17 (from selenium>=4.18.1->crewai-tools)\n",
            "  Downloading trio-0.27.0-py3-none-any.whl.metadata (8.6 kB)\n",
            "Collecting trio-websocket~=0.9 (from selenium>=4.18.1->crewai-tools)\n",
            "  Downloading trio_websocket-0.11.1-py3-none-any.whl.metadata (4.7 kB)\n",
            "Requirement already satisfied: websocket-client~=1.8 in /usr/local/lib/python3.10/dist-packages (from selenium>=4.18.1->crewai-tools) (1.8.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.5->auth0-python>=4.7.1->crewai) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.5->auth0-python>=4.7.1->crewai) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.5->auth0-python>=4.7.1->crewai) (4.0.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.5->auth0-python>=4.7.1->crewai) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.5->auth0-python>=4.7.1->crewai) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.5->auth0-python>=4.7.1->crewai) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.5->auth0-python>=4.7.1->crewai) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.5->auth0-python>=4.7.1->crewai) (1.18.3)\n",
            "Collecting Mako (from alembic<2.0.0,>=1.13.1->embedchain>=0.1.114->crewai-tools)\n",
            "  Downloading Mako-1.3.8-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting pyproject_hooks (from build>=1.0.3->chromadb>=0.5.18->crewai)\n",
            "  Downloading pyproject_hooks-1.2.0-py3-none-any.whl.metadata (1.3 kB)\n",
            "Collecting fastavro<2.0.0,>=1.9.4 (from cohere<6.0,>=5.3->embedchain>=0.1.114->crewai-tools)\n",
            "  Downloading fastavro-1.9.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.5 kB)\n",
            "Collecting httpx-sse==0.4.0 (from cohere<6.0,>=5.3->embedchain>=0.1.114->crewai-tools)\n",
            "  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
            "Collecting parameterized<0.10.0,>=0.9.0 (from cohere<6.0,>=5.3->embedchain>=0.1.114->crewai-tools)\n",
            "  Downloading parameterized-0.9.0-py2.py3-none-any.whl.metadata (18 kB)\n",
            "Collecting types-requests<3.0.0,>=2.0.0 (from cohere<6.0,>=5.3->embedchain>=0.1.114->crewai-tools)\n",
            "  Downloading types_requests-2.32.0.20241016-py3-none-any.whl.metadata (1.9 kB)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography<44.0.0,>=43.0.1->auth0-python>=4.7.1->crewai) (1.17.1)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.10/dist-packages (from deprecated>=1.2.6->opentelemetry-api>=1.22.0->crewai) (1.17.0)\n",
            "Collecting starlette<0.42.0,>=0.40.0 (from fastapi>=0.95.2->chromadb>=0.5.18->crewai)\n",
            "  Downloading starlette-0.41.3-py3-none-any.whl.metadata (6.0 kB)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain>=0.1.114->crewai-tools) (2.19.2)\n",
            "Requirement already satisfied: google-auth<3.0.0dev,>=2.14.1 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain>=0.1.114->crewai-tools) (2.27.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain>=0.1.114->crewai-tools) (1.25.0)\n",
            "Requirement already satisfied: google-cloud-storage<3.0.0dev,>=1.32.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain>=0.1.114->crewai-tools) (2.8.0)\n",
            "Requirement already satisfied: google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain>=0.1.114->crewai-tools) (3.25.0)\n",
            "Requirement already satisfied: google-cloud-resource-manager<3.0.0dev,>=1.3.3 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain>=0.1.114->crewai-tools) (1.13.1)\n",
            "Requirement already satisfied: shapely<3.0.0dev in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain>=0.1.114->crewai-tools) (2.0.6)\n",
            "Requirement already satisfied: cachetools in /usr/local/lib/python3.10/dist-packages (from gptcache<0.2.0,>=0.1.43->embedchain>=0.1.114->crewai-tools) (5.5.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx>=0.27.0->chromadb>=0.5.18->crewai) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx>=0.27.0->chromadb>=0.5.18->crewai) (0.14.0)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata>=6.8.0->litellm>=1.44.22->crewai) (3.21.0)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.10/dist-packages (from ipython>=5.3.0->pyvis>=0.3.2->crewai) (75.1.0)\n",
            "Collecting jedi>=0.16 (from ipython>=5.3.0->pyvis>=0.3.2->crewai)\n",
            "  Downloading jedi-0.19.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython>=5.3.0->pyvis>=0.3.2->crewai) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython>=5.3.0->pyvis>=0.3.2->crewai) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.10/dist-packages (from ipython>=5.3.0->pyvis>=0.3.2->crewai) (5.7.1)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython>=5.3.0->pyvis>=0.3.2->crewai) (3.0.48)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython>=5.3.0->pyvis>=0.3.2->crewai) (2.18.0)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython>=5.3.0->pyvis>=0.3.2->crewai) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython>=5.3.0->pyvis>=0.3.2->crewai) (0.1.7)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython>=5.3.0->pyvis>=0.3.2->crewai) (4.9.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2<4.0.0,>=3.1.4->instructor>=1.3.3->crewai) (3.0.2)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema<5.0.0,>=4.22.0->litellm>=1.44.22->crewai) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema<5.0.0,>=4.22.0->litellm>=1.44.22->crewai) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema<5.0.0,>=4.22.0->litellm>=1.44.22->crewai) (0.22.3)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb>=0.5.18->crewai) (1.16.0)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb>=0.5.18->crewai) (2.8.2)\n",
            "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb>=0.5.18->crewai) (1.3.1)\n",
            "Requirement already satisfied: oauthlib>=3.2.2 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb>=0.5.18->crewai) (3.2.2)\n",
            "Collecting durationpy>=0.7 (from kubernetes>=28.1.0->chromadb>=0.5.18->crewai)\n",
            "  Downloading durationpy-0.9-py3-none-any.whl.metadata (338 bytes)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.21 in /usr/local/lib/python3.10/dist-packages (from langchain<0.4.0,>=0.3.1->embedchain>=0.1.114->crewai-tools) (0.3.21)\n",
            "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from langchain<0.4.0,>=0.3.1->embedchain>=0.1.114->crewai-tools) (0.3.2)\n",
            "Collecting langchain-experimental<0.4.0,>=0.3.0 (from langchain-cohere<0.4.0,>=0.3.0->embedchain>=0.1.114->crewai-tools)\n",
            "  Downloading langchain_experimental-0.3.3-py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: pandas>=1.4.3 in /usr/local/lib/python3.10/dist-packages (from langchain-cohere<0.4.0,>=0.3.0->embedchain>=0.1.114->crewai-tools) (2.2.2)\n",
            "Requirement already satisfied: tabulate<0.10.0,>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from langchain-cohere<0.4.0,>=0.3.0->embedchain>=0.1.114->crewai-tools) (0.9.0)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain-community<0.4.0,>=0.3.1->embedchain>=0.1.114->crewai-tools)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting langchain<0.4.0,>=0.3.1 (from embedchain>=0.1.114->crewai-tools)\n",
            "  Downloading langchain-0.3.10-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting langchain-core<0.4.0,>=0.3.21 (from langchain<0.4.0,>=0.3.1->embedchain>=0.1.114->crewai-tools)\n",
            "  Downloading langchain_core-0.3.22-py3-none-any.whl.metadata (6.3 kB)\n",
            "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain-community<0.4.0,>=0.3.1->embedchain>=0.1.114->crewai-tools)\n",
            "  Downloading pydantic_settings-2.6.1-py3-none-any.whl.metadata (3.5 kB)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.17->embedchain>=0.1.114->crewai-tools) (1.0.0)\n",
            "Requirement already satisfied: pytz<2025.0,>=2024.1 in /usr/local/lib/python3.10/dist-packages (from mem0ai<0.2.0,>=0.1.29->embedchain>=0.1.114->crewai-tools) (2024.2)\n",
            "Collecting qdrant-client<2.0.0,>=1.9.1 (from mem0ai<0.2.0,>=0.1.29->embedchain>=0.1.114->crewai-tools)\n",
            "  Downloading qdrant_client-1.12.1-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting coloredlogs (from onnxruntime>=1.14.1->chromadb>=0.5.18->crewai)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb>=0.5.18->crewai) (24.3.25)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb>=0.5.18->crewai) (1.13.1)\n",
            "Collecting opentelemetry-instrumentation-asgi==0.49b2 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb>=0.5.18->crewai)\n",
            "  Downloading opentelemetry_instrumentation_asgi-0.49b2-py3-none-any.whl.metadata (1.9 kB)\n",
            "Collecting opentelemetry-instrumentation==0.49b2 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb>=0.5.18->crewai)\n",
            "  Downloading opentelemetry_instrumentation-0.49b2-py3-none-any.whl.metadata (6.1 kB)\n",
            "Collecting opentelemetry-util-http==0.49b2 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb>=0.5.18->crewai)\n",
            "  Downloading opentelemetry_util_http-0.49b2-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting asgiref~=3.0 (from opentelemetry-instrumentation-asgi==0.49b2->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb>=0.5.18->crewai)\n",
            "  Downloading asgiref-3.8.1-py3-none-any.whl.metadata (9.3 kB)\n",
            "Collecting monotonic>=1.5 (from posthog>=2.4.0->chromadb>=0.5.18->crewai)\n",
            "  Downloading monotonic-1.6-py2.py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting backoff>=1.10.0 (from posthog>=2.4.0->chromadb>=0.5.18->crewai)\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->chromadb>=0.5.18->crewai) (3.0.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy<3.0.0,>=2.0.27->embedchain>=0.1.114->crewai-tools) (3.1.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from tokenizers<=0.20.3,>=0.13.2->chromadb>=0.5.18->crewai) (0.26.3)\n",
            "Collecting sortedcontainers (from trio~=0.17->selenium>=4.18.1->crewai-tools)\n",
            "  Downloading sortedcontainers-2.4.0-py2.py3-none-any.whl.metadata (10 kB)\n",
            "Collecting outcome (from trio~=0.17->selenium>=4.18.1->crewai-tools)\n",
            "  Downloading outcome-1.3.0.post0-py2.py3-none-any.whl.metadata (2.6 kB)\n",
            "Collecting wsproto>=0.14 (from trio-websocket~=0.9->selenium>=4.18.1->crewai-tools)\n",
            "  Downloading wsproto-1.2.0-py3-none-any.whl.metadata (5.6 kB)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer>=0.9.0->chromadb>=0.5.18->crewai) (1.5.4)\n",
            "Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from urllib3[socks]<3,>=1.26->selenium>=4.18.1->crewai-tools) (1.7.1)\n",
            "Collecting httptools>=0.6.3 (from uvicorn[standard]>=0.18.3->chromadb>=0.5.18->crewai)\n",
            "  Downloading httptools-0.6.4-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
            "Collecting uvloop!=0.15.0,!=0.15.1,>=0.14.0 (from uvicorn[standard]>=0.18.3->chromadb>=0.5.18->crewai)\n",
            "  Downloading uvloop-0.21.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Collecting watchfiles>=0.13 (from uvicorn[standard]>=0.18.3->chromadb>=0.5.18->crewai)\n",
            "  Downloading watchfiles-1.0.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Collecting websockets>=10.4 (from uvicorn[standard]>=0.18.3->chromadb>=0.5.18->crewai)\n",
            "  Downloading websockets-14.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography<44.0.0,>=43.0.1->auth0-python>=4.7.1->crewai) (2.22)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community<0.4.0,>=0.3.1->embedchain>=0.1.114->crewai-tools)\n",
            "  Downloading marshmallow-3.23.1-py3-none-any.whl.metadata (7.5 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community<0.4.0,>=0.3.1->embedchain>=0.1.114->crewai-tools)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain>=0.1.114->crewai-tools) (1.62.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain>=0.1.114->crewai-tools) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain>=0.1.114->crewai-tools) (4.9)\n",
            "Requirement already satisfied: google-cloud-core<3.0.0dev,>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain>=0.1.114->crewai-tools) (2.4.1)\n",
            "Requirement already satisfied: google-resumable-media<3.0dev,>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain>=0.1.114->crewai-tools) (2.7.2)\n",
            "Requirement already satisfied: grpc-google-iam-v1<1.0.0dev,>=0.12.4 in /usr/local/lib/python3.10/dist-packages (from google-cloud-resource-manager<3.0.0dev,>=1.3.3->google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain>=0.1.114->crewai-tools) (0.13.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<=0.20.3,>=0.13.2->chromadb>=0.5.18->crewai) (3.16.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<=0.20.3,>=0.13.2->chromadb>=0.5.18->crewai) (2024.10.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython>=5.3.0->pyvis>=0.3.2->crewai) (0.8.4)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.21->langchain<0.4.0,>=0.3.1->embedchain>=0.1.114->crewai-tools) (1.33)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb>=0.5.18->crewai) (0.1.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.4.3->langchain-cohere<0.4.0,>=0.3.0->embedchain>=0.1.114->crewai-tools) (2024.2)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython>=5.3.0->pyvis>=0.3.2->crewai) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=5.3.0->pyvis>=0.3.2->crewai) (0.2.13)\n",
            "Collecting grpcio-tools>=1.41.0 (from qdrant-client<2.0.0,>=1.9.1->mem0ai<0.2.0,>=0.1.29->embedchain>=0.1.114->crewai-tools)\n",
            "  Downloading grpcio_tools-1.68.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.3 kB)\n",
            "Collecting portalocker<3.0.0,>=2.7.0 (from qdrant-client<2.0.0,>=1.9.1->mem0ai<0.2.0,>=0.1.29->embedchain>=0.1.114->crewai-tools)\n",
            "  Downloading portalocker-2.10.1-py3-none-any.whl.metadata (8.5 kB)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.14.1->chromadb>=0.5.18->crewai)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb>=0.5.18->crewai) (1.3.0)\n",
            "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /usr/local/lib/python3.10/dist-packages (from google-resumable-media<3.0dev,>=0.6.0->google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain>=0.1.114->crewai-tools) (1.6.0)\n",
            "Collecting h2<5,>=3 (from httpx[http2]>=0.20.0->qdrant-client<2.0.0,>=1.9.1->mem0ai<0.2.0,>=0.1.29->embedchain>=0.1.114->crewai-tools)\n",
            "  Downloading h2-4.1.0-py3-none-any.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.21->langchain<0.4.0,>=0.3.1->embedchain>=0.1.114->crewai-tools) (3.0.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain>=0.1.114->crewai-tools) (0.6.1)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community<0.4.0,>=0.3.1->embedchain>=0.1.114->crewai-tools)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Collecting hyperframe<7,>=6.0 (from h2<5,>=3->httpx[http2]>=0.20.0->qdrant-client<2.0.0,>=1.9.1->mem0ai<0.2.0,>=0.1.29->embedchain>=0.1.114->crewai-tools)\n",
            "  Downloading hyperframe-6.0.1-py3-none-any.whl.metadata (2.7 kB)\n",
            "Collecting hpack<5,>=4.0 (from h2<5,>=3->httpx[http2]>=0.20.0->qdrant-client<2.0.0,>=1.9.1->mem0ai<0.2.0,>=0.1.29->embedchain>=0.1.114->crewai-tools)\n",
            "  Downloading hpack-4.0.0-py3-none-any.whl.metadata (2.5 kB)\n",
            "Downloading crewai-0.86.0-py3-none-any.whl (192 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m192.0/192.0 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading crewai_tools-0.17.0-py3-none-any.whl (467 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m468.0/468.0 kB\u001b[0m \u001b[31m22.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\n",
            "Downloading auth0_python-4.7.2-py3-none-any.whl (131 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m131.8/131.8 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading chromadb-0.5.23-py3-none-any.whl (628 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m628.3/628.3 kB\u001b[0m \u001b[31m35.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading chroma_hnswlib-0.7.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m63.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading docker-7.1.0-py3-none-any.whl (147 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m147.8/147.8 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading embedchain-0.1.125-py3-none-any.whl (211 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.4/211.4 kB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading instructor-1.7.0-py3-none-any.whl (70 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.1/70.1 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading json_repair-0.30.3-py3-none-any.whl (18 kB)\n",
            "Downloading jsonref-1.1.0-py3-none-any.whl (9.4 kB)\n",
            "Downloading lancedb-0.17.0-cp39-abi3-manylinux_2_28_x86_64.whl (29.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m29.9/29.9 MB\u001b[0m \u001b[31m53.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pylance-0.20.0-cp39-abi3-manylinux_2_28_x86_64.whl (33.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m33.5/33.5 MB\u001b[0m \u001b[31m22.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading litellm-1.54.0-py3-none-any.whl (6.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.4/6.4 MB\u001b[0m \u001b[31m85.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading openai-1.57.0-py3-none-any.whl (389 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m389.9/389.9 kB\u001b[0m \u001b[31m25.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_exporter_otlp_proto_http-1.28.2-py3-none-any.whl (17 kB)\n",
            "Downloading opentelemetry_exporter_otlp_proto_common-1.28.2-py3-none-any.whl (18 kB)\n",
            "Downloading opentelemetry_proto-1.28.2-py3-none-any.whl (55 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.8/55.8 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pdfplumber-0.11.4-py3-none-any.whl (59 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.2/59.2 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pdfminer.six-20231228-py3-none-any.whl (5.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m92.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyright-1.1.390-py3-none-any.whl (18 kB)\n",
            "Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Downloading pytube-15.0.0-py3-none-any.whl (57 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.6/57.6 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyvis-0.3.2-py3-none-any.whl (756 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m756.0/756.0 kB\u001b[0m \u001b[31m43.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading selenium-4.27.1-py3-none-any.whl (9.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.7/9.7 MB\u001b[0m \u001b[31m78.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tomli_w-1.1.0-py3-none-any.whl (6.4 kB)\n",
            "Downloading uv-0.5.7-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (14.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.7/14.7 MB\u001b[0m \u001b[31m84.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading alembic-1.14.0-py3-none-any.whl (233 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.5/233.5 kB\u001b[0m \u001b[31m18.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading bcrypt-4.2.1-cp39-abi3-manylinux_2_28_x86_64.whl (278 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m278.6/278.6 kB\u001b[0m \u001b[31m19.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading build-1.2.2.post1-py3-none-any.whl (22 kB)\n",
            "Downloading cohere-5.13.3-py3-none-any.whl (249 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m249.9/249.9 kB\u001b[0m \u001b[31m20.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
            "Downloading fastapi-0.115.6-py3-none-any.whl (94 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.8/94.8 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gptcache-0.1.44-py3-none-any.whl (131 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m131.6/131.6 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpx-0.27.2-py3-none-any.whl (76 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.4/76.4 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jiter-0.6.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (325 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m325.2/325.2 kB\u001b[0m \u001b[31m22.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading kubernetes-31.0.0-py2.py3-none-any.whl (1.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m63.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_cohere-0.3.3-py3-none-any.whl (44 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.3/44.3 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_community-0.3.10-py3-none-any.whl (2.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m74.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain-0.3.10-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m44.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_openai-0.2.11-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.7/50.7 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mem0ai-0.1.34-py3-none-any.whl (83 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.2/83.2 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mmh3-5.0.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (93 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.2/93.2 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nodeenv-1.9.1-py2.py3-none-any.whl (22 kB)\n",
            "Downloading onnxruntime-1.20.1-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (13.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.3/13.3 MB\u001b[0m \u001b[31m24.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_exporter_otlp_proto_grpc-1.28.2-py3-none-any.whl (18 kB)\n",
            "Downloading opentelemetry_instrumentation_fastapi-0.49b2-py3-none-any.whl (12 kB)\n",
            "Downloading opentelemetry_instrumentation-0.49b2-py3-none-any.whl (30 kB)\n",
            "Downloading opentelemetry_instrumentation_asgi-0.49b2-py3-none-any.whl (16 kB)\n",
            "Downloading opentelemetry_util_http-0.49b2-py3-none-any.whl (6.9 kB)\n",
            "Downloading overrides-7.7.0-py3-none-any.whl (17 kB)\n",
            "Downloading posthog-3.7.4-py2.py3-none-any.whl (54 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.8/54.8 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pypdf-5.1.0-py3-none-any.whl (297 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m298.0/298.0 kB\u001b[0m \u001b[31m21.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pypdfium2-4.30.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m76.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pysbd-0.3.4-py3-none-any.whl (71 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.1/71.1 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading schema-0.7.7-py2.py3-none-any.whl (18 kB)\n",
            "Downloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m41.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading trio-0.27.0-py3-none-any.whl (481 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m481.7/481.7 kB\u001b[0m \u001b[31m29.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading trio_websocket-0.11.1-py3-none-any.whl (17 kB)\n",
            "Downloading uvicorn-0.32.1-py3-none-any.whl (63 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.8/63.8 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading deprecation-2.1.0-py2.py3-none-any.whl (11 kB)\n",
            "Downloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading durationpy-0.9-py3-none-any.whl (3.5 kB)\n",
            "Downloading fastavro-1.9.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m82.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httptools-0.6.4-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (442 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m442.1/442.1 kB\u001b[0m \u001b[31m27.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jedi-0.19.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m61.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_core-0.3.22-py3-none-any.whl (409 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m409.7/409.7 kB\u001b[0m \u001b[31m28.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_experimental-0.3.3-py3-none-any.whl (208 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.0/209.0 kB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\n",
            "Downloading parameterized-0.9.0-py2.py3-none-any.whl (20 kB)\n",
            "Downloading protobuf-5.29.1-cp38-abi3-manylinux2014_x86_64.whl (319 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m319.7/319.7 kB\u001b[0m \u001b[31m23.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydantic_settings-2.6.1-py3-none-any.whl (28 kB)\n",
            "Downloading qdrant_client-1.12.1-py3-none-any.whl (267 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m267.2/267.2 kB\u001b[0m \u001b[31m18.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading starlette-0.41.3-py3-none-any.whl (73 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.2/73.2 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading types_requests-2.32.0.20241016-py3-none-any.whl (15 kB)\n",
            "Downloading uvloop-0.21.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m79.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading watchfiles-1.0.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (442 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m442.6/442.6 kB\u001b[0m \u001b[31m28.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading websockets-14.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (168 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.2/168.2 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading wsproto-1.2.0-py3-none-any.whl (24 kB)\n",
            "Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading Mako-1.3.8-py3-none-any.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.6/78.6 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading outcome-1.3.0.post0-py2.py3-none-any.whl (10 kB)\n",
            "Downloading pyproject_hooks-1.2.0-py3-none-any.whl (10 kB)\n",
            "Downloading sortedcontainers-2.4.0-py2.py3-none-any.whl (29 kB)\n",
            "Downloading asgiref-3.8.1-py3-none-any.whl (23 kB)\n",
            "Downloading grpcio_tools-1.68.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m66.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading marshmallow-3.23.1-py3-none-any.whl (49 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.5/49.5 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading portalocker-2.10.1-py3-none-any.whl (18 kB)\n",
            "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading h2-4.1.0-py3-none-any.whl (57 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.5/57.5 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Downloading hpack-4.0.0-py3-none-any.whl (32 kB)\n",
            "Downloading hyperframe-6.0.1-py3-none-any.whl (12 kB)\n",
            "Building wheels for collected packages: docx2txt, pypika\n",
            "  Building wheel for docx2txt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for docx2txt: filename=docx2txt-0.8-py3-none-any.whl size=3960 sha256=06492e82d57048d88a26190e4cbcc67078a11526a05fd10f38d6f7684efeaf73\n",
            "  Stored in directory: /root/.cache/pip/wheels/22/58/cf/093d0a6c3ecfdfc5f6ddd5524043b88e59a9a199cb02352966\n",
            "  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pypika: filename=PyPika-0.48.9-py2.py3-none-any.whl size=53725 sha256=3f2211a6add02150b47324695542832b26d0daf9b34e271dc13fff26d78f3de7\n",
            "  Stored in directory: /root/.cache/pip/wheels/e1/26/51/d0bffb3d2fd82256676d7ad3003faea3bd6dddc9577af665f4\n",
            "Successfully built docx2txt pypika\n",
            "Installing collected packages: sortedcontainers, schema, pypika, monotonic, durationpy, docx2txt, appdirs, wsproto, websockets, uvloop, uvicorn, uv, types-requests, tomli-w, pytube, python-dotenv, pysbd, pyproject_hooks, pypdfium2, pypdf, protobuf, portalocker, parameterized, overrides, outcome, opentelemetry-util-http, nodeenv, mypy-extensions, mmh3, marshmallow, Mako, jsonref, json-repair, jiter, jedi, hyperframe, humanfriendly, httpx-sse, httptools, hpack, fastavro, deprecation, chroma-hnswlib, bcrypt, backoff, asgiref, watchfiles, typing-inspect, trio, tiktoken, starlette, pyright, pylance, posthog, opentelemetry-proto, httpx, h2, grpcio-tools, gptcache, docker, coloredlogs, build, alembic, trio-websocket, pyvis, pydantic-settings, pdfminer.six, opentelemetry-exporter-otlp-proto-common, openai, onnxruntime, lancedb, kubernetes, fastapi, dataclasses-json, selenium, qdrant-client, pdfplumber, opentelemetry-instrumentation, litellm, langchain-core, instructor, cohere, auth0-python, opentelemetry-instrumentation-asgi, opentelemetry-exporter-otlp-proto-http, opentelemetry-exporter-otlp-proto-grpc, mem0ai, langchain-openai, opentelemetry-instrumentation-fastapi, langchain, langchain-community, chromadb, langchain-experimental, langchain-cohere, embedchain, crewai-tools, crewai\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 4.25.5\n",
            "    Uninstalling protobuf-4.25.5:\n",
            "      Successfully uninstalled protobuf-4.25.5\n",
            "  Attempting uninstall: jiter\n",
            "    Found existing installation: jiter 0.8.0\n",
            "    Uninstalling jiter-0.8.0:\n",
            "      Successfully uninstalled jiter-0.8.0\n",
            "  Attempting uninstall: httpx\n",
            "    Found existing installation: httpx 0.28.0\n",
            "    Uninstalling httpx-0.28.0:\n",
            "      Successfully uninstalled httpx-0.28.0\n",
            "  Attempting uninstall: openai\n",
            "    Found existing installation: openai 1.54.5\n",
            "    Uninstalling openai-1.54.5:\n",
            "      Successfully uninstalled openai-1.54.5\n",
            "  Attempting uninstall: langchain-core\n",
            "    Found existing installation: langchain-core 0.3.21\n",
            "    Uninstalling langchain-core-0.3.21:\n",
            "      Successfully uninstalled langchain-core-0.3.21\n",
            "  Attempting uninstall: langchain\n",
            "    Found existing installation: langchain 0.3.9\n",
            "    Uninstalling langchain-0.3.9:\n",
            "      Successfully uninstalled langchain-0.3.9\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.17.1 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3, but you have protobuf 5.29.1 which is incompatible.\n",
            "tensorflow-metadata 1.13.1 requires protobuf<5,>=3.20.3, but you have protobuf 5.29.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed Mako-1.3.8 alembic-1.14.0 appdirs-1.4.4 asgiref-3.8.1 auth0-python-4.7.2 backoff-2.2.1 bcrypt-4.2.1 build-1.2.2.post1 chroma-hnswlib-0.7.6 chromadb-0.5.23 cohere-5.13.3 coloredlogs-15.0.1 crewai-0.86.0 crewai-tools-0.17.0 dataclasses-json-0.6.7 deprecation-2.1.0 docker-7.1.0 docx2txt-0.8 durationpy-0.9 embedchain-0.1.125 fastapi-0.115.6 fastavro-1.9.7 gptcache-0.1.44 grpcio-tools-1.68.1 h2-4.1.0 hpack-4.0.0 httptools-0.6.4 httpx-0.27.2 httpx-sse-0.4.0 humanfriendly-10.0 hyperframe-6.0.1 instructor-1.7.0 jedi-0.19.2 jiter-0.6.1 json-repair-0.30.3 jsonref-1.1.0 kubernetes-31.0.0 lancedb-0.17.0 langchain-0.3.10 langchain-cohere-0.3.3 langchain-community-0.3.10 langchain-core-0.3.22 langchain-experimental-0.3.3 langchain-openai-0.2.11 litellm-1.54.0 marshmallow-3.23.1 mem0ai-0.1.34 mmh3-5.0.1 monotonic-1.6 mypy-extensions-1.0.0 nodeenv-1.9.1 onnxruntime-1.20.1 openai-1.57.0 opentelemetry-exporter-otlp-proto-common-1.28.2 opentelemetry-exporter-otlp-proto-grpc-1.28.2 opentelemetry-exporter-otlp-proto-http-1.28.2 opentelemetry-instrumentation-0.49b2 opentelemetry-instrumentation-asgi-0.49b2 opentelemetry-instrumentation-fastapi-0.49b2 opentelemetry-proto-1.28.2 opentelemetry-util-http-0.49b2 outcome-1.3.0.post0 overrides-7.7.0 parameterized-0.9.0 pdfminer.six-20231228 pdfplumber-0.11.4 portalocker-2.10.1 posthog-3.7.4 protobuf-5.29.1 pydantic-settings-2.6.1 pylance-0.20.0 pypdf-5.1.0 pypdfium2-4.30.0 pypika-0.48.9 pyproject_hooks-1.2.0 pyright-1.1.390 pysbd-0.3.4 python-dotenv-1.0.1 pytube-15.0.0 pyvis-0.3.2 qdrant-client-1.12.1 schema-0.7.7 selenium-4.27.1 sortedcontainers-2.4.0 starlette-0.41.3 tiktoken-0.7.0 tomli-w-1.1.0 trio-0.27.0 trio-websocket-0.11.1 types-requests-2.32.0.20241016 typing-inspect-0.9.0 uv-0.5.7 uvicorn-0.32.1 uvloop-0.21.0 watchfiles-1.0.0 websockets-14.1 wsproto-1.2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "import os\n",
        "os.environ['OPENAI_API_KEY']=userdata.get('OPENAI_API_KEY')"
      ],
      "metadata": {
        "id": "Jmtv0xvkmFk2"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "pHHdC2mqlrxC"
      },
      "outputs": [],
      "source": [
        "from crewai import Agent, Task, Crew"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "support_agent = Agent(\n",
        "    role=\"Senior Support Representative\",\n",
        "\tgoal=\"Be the most friendly and helpful \"\n",
        "        \"support representative in your team\",\n",
        "\tbackstory=(\n",
        "\t\t\"You work at {employer_name} and \"\n",
        "        \" are now working on providing \"\n",
        "\t\t\"support to {customer}, a super important customer \"\n",
        "        \" for your company.\"\n",
        "\t\t\"You need to make sure that you provide the best support!\"\n",
        "\t\t\"Make sure to provide full complete answers, \"\n",
        "        \" and make no assumptions.\"\n",
        "\t),\n",
        "\tallow_delegation=False,\n",
        "\tverbose=True\n",
        ")"
      ],
      "metadata": {
        "id": "b1E4wtO9pON1"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "support_quality_assurance_agent = Agent(\n",
        "\trole=\"Support Quality Assurance Specialist\",\n",
        "\tgoal=\"Get recognition for providing the \"\n",
        "    \"best support quality assurance in your team\",\n",
        "\tbackstory=(\n",
        "\t\t\"You work at crewAI {employer_name} and \"\n",
        "        \"are now working with your team \"\n",
        "\t\t\"on a request from {customer} ensuring that \"\n",
        "        \"the support representative is \"\n",
        "\t\t\"providing the best support possible.\\n\"\n",
        "\t\t\"You need to make sure that the support representative \"\n",
        "        \"is providing full\"\n",
        "\t\t\"complete answers, and make no assumptions.\"\n",
        "\t),\n",
        "\tverbose=True\n",
        ")"
      ],
      "metadata": {
        "id": "35eWwbC_q3le"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from crewai_tools import SerperDevTool, \\\n",
        "                         ScrapeWebsiteTool, \\\n",
        "                         WebsiteSearchTool"
      ],
      "metadata": {
        "id": "MA3_AokerE92"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "search_tool = SerperDevTool()\n",
        "scrape_tool = ScrapeWebsiteTool()"
      ],
      "metadata": {
        "id": "l2kpsDElrJgQ"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "maersk_ocean_api_doc_tool = ScrapeWebsiteTool(\n",
        "    website_url=\"https://docs.crewai.com/quickstart\"\n",
        ")"
      ],
      "metadata": {
        "id": "I9MW0jECrPoN"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Different Ways to Give Agents Tools\n",
        "\n",
        "- Agent Level: The Agent can use the Tool(s) on any Task it performs.\n",
        "- Task Level: The Agent will only use the Tool(s) when performing that specific Task.\n",
        "\n",
        "**Note**: Task Tools override the Agent Tools."
      ],
      "metadata": {
        "id": "ym_x3q22rkQx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inquiry_resolution_task = Task(\n",
        "    description=(\n",
        "        \"{customer} just reached out with a super important ask:\\n\"\n",
        "\t    \"{inquiry}\\n\\n\"\n",
        "        \"{person} from {customer} is the one that reached out. \"\n",
        "\t\t\"Make sure to use everything you know \"\n",
        "        \"to provide the best support possible.\"\n",
        "\t\t\"You must strive to provide a complete \"\n",
        "        \"and accurate response to the customer's inquiry.\"\n",
        "    ),\n",
        "    expected_output=(\n",
        "\t    \"A detailed, informative response to the \"\n",
        "        \"customer's inquiry that addresses \"\n",
        "        \"all aspects of their question.\\n\"\n",
        "        \"The response should include references \"\n",
        "        \"to everything you used to find the answer, \"\n",
        "        \"including external data or solutions. \"\n",
        "        \"Ensure the answer is complete, \"\n",
        "\t\t\"leaving no questions unanswered, and maintain a helpful and friendly \"\n",
        "\t\t\"tone throughout.\"\n",
        "    ),\n",
        "\ttools=[maersk_ocean_api_doc_tool],\n",
        "    agent=support_agent,\n",
        ")"
      ],
      "metadata": {
        "id": "sMO3vbM5rk8m"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "quality_assurance_review = Task(\n",
        "    description=(\n",
        "        \"Review the response drafted by the Senior Support Representative for {customer}'s inquiry. \"\n",
        "        \"Ensure that the answer is comprehensive, accurate, and adheres to the \"\n",
        "\t\t\"high-quality standards expected for customer support.\\n\"\n",
        "        \"Verify that all parts of the customer's inquiry \"\n",
        "        \"have been addressed \"\n",
        "\t\t\"thoroughly, with a helpful and friendly tone.\\n\"\n",
        "        \"Check for references and sources used to \"\n",
        "        \" find the information, \"\n",
        "\t\t\"ensuring the response is well-supported and \"\n",
        "        \"leaves no questions unanswered.\"\n",
        "    ),\n",
        "    expected_output=(\n",
        "        \"A final, detailed, and informative response \"\n",
        "        \"ready to be sent to the customer.\\n\"\n",
        "        \"This response should fully address the \"\n",
        "        \"customer's inquiry, incorporating all \"\n",
        "\t\t\"relevant feedback and improvements.\\n\"\n",
        "\t\t\"Don't be too formal, we are a chill and cool company \"\n",
        "\t    \"but maintain a professional and friendly tone throughout.\"\n",
        "    ),\n",
        "    agent=support_quality_assurance_agent,\n",
        ")\n"
      ],
      "metadata": {
        "id": "nHEGlWA9rgfi"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creating the Crew\n",
        "\n",
        "#### Memory\n",
        "- Setting `memory=True` when putting the crew together enables Memory."
      ],
      "metadata": {
        "id": "xAS2S_iqsc28"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "crew = Crew(\n",
        "  agents=[support_agent, support_quality_assurance_agent],\n",
        "  tasks=[inquiry_resolution_task, quality_assurance_review],\n",
        "  verbose=True,\n",
        "  memory=True\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "--jhKrarsdhh",
        "outputId": "0f6ce5e2-ae04-45b8-c748-2f2689fa3f95"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:opentelemetry.trace:Overriding of current TracerProvider is not allowed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = {\n",
        "    \"employer_name\": \"CrewAI\",\n",
        "    \"customer\": \"Maersk\",\n",
        "    \"person\": \"Bhanu\",\n",
        "    \"inquiry\": \"I need help with setting up a Crew AI \"\n",
        "               \"Can you tell how to setup multiple agents which colaborate? \"\n",
        "               \"Can you also provide how to use memory in agents?\"\n",
        "}\n",
        "result = crew.kickoff(inputs=inputs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B5esmV7bsoKq",
        "outputId": "bf4dbf13-bd32-4b6c-e0ff-b0bff1306bb0"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mSenior Support Representative\u001b[00m\n",
            "\u001b[95m## Task:\u001b[00m \u001b[92mMaersk just reached out with a super important ask:\n",
            "I need help with setting up a Crew AI Can you tell how to setup multiple agents which colaborate? Can you also provide how to use memory in agents?\n",
            "\n",
            "Bhanu from Maersk is the one that reached out. Make sure to use everything you know to provide the best support possible.You must strive to provide a complete and accurate response to the customer's inquiry.\u001b[00m\n",
            "\n",
            "\n",
            "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mSenior Support Representative\u001b[00m\n",
            "\u001b[95m## Thought:\u001b[00m \u001b[92mI need to gather information on how to set up multiple agents that collaborate and how to use memory in agents within CrewAI. This will provide Bhanu from Maersk a detailed, informative response to her inquiry.\u001b[00m\n",
            "\u001b[95m## Using tool:\u001b[00m \u001b[92mRead website content\u001b[00m\n",
            "\u001b[95m## Tool Input:\u001b[00m \u001b[92m\n",
            "\"{}\"\u001b[00m\n",
            "\u001b[95m## Tool Output:\u001b[00m \u001b[92m\n",
            "Quickstart - CrewAI CrewAI home page Search CrewAI docs crewAIInc / crewAI crewAIInc / crewAI Search... Navigation Get Started Quickstart Get Started Examples CrewAI home page Community Changelog Get Started Introduction Installation Quickstart Core Concepts Agents Tasks Crews Flows Knowledge LLMs Processes Collaboration Training Memory Planning Testing CLI Tools Using LangChain Tools Using LlamaIndex Tools How to Guides Create Custom Tools Sequential Processes Hierarchical Process Create Your Own Manager Agent Connect to any LLM Customize Agents Coding Agents Force Tool Output as Result Human Input on Execution Kickoff Crew Asynchronously Kickoff Crew for Each Replay Tasks from Latest Crew Kickoff Conditional Tasks Agent Monitoring with AgentOps Agent Monitoring with Langtrace Agent Monitoring with OpenLIT Tools Browserbase Web Loader Code Docs RAG Search Code Interpreter Composio Tool CSV RAG Search DALL-E Tool Directory RAG Search Directory Read DOCX RAG Search EXA Search Web Loader File Read File Write Firecrawl Crawl Website Firecrawl Scrape Website Firecrawl Search Github Search Google Serper Search JSON RAG Search MDX RAG Search MySQL RAG Search NL2SQL Tool PDF RAG Search PG RAG Search Scrape Website Selenium Scraper Spider Scraper TXT RAG Search Vision Tool Website RAG Search XML RAG Search YouTube Channel RAG Search YouTube Video RAG Search Telemetry Telemetry Get Started Quickstart Build your first AI agent with CrewAI in under 5 minutes. ‚Äã Build your first CrewAI Agent\n",
            "Let‚Äôs create a simple crew that will help us research and report on the latest AI developments for a given topic or subject.\n",
            "Before we proceed, make sure you have crewai and crewai-tools installed.\n",
            "If you haven‚Äôt installed them yet, you can do so by following the installation guide .\n",
            "Follow the steps below to get crewing! üö£‚Äç‚ôÇÔ∏è\n",
            "1 Create your crew Create a new crew project by running the following command in your terminal.\n",
            "This will create a new directory called latest-ai-development with the basic structure for your crew. 2 Modify your `agents.yaml` file You can also modify the agents as needed to fit your use case or copy and paste as is to your project.\n",
            "Any variable interpolated in your agents.yaml and tasks.yaml files like {topic} will be replaced by the value of the variable in the main.py file. agents.yaml # src/latest_ai_development/config/agents.yaml\n",
            "researcher :\n",
            "role : >\n",
            "{ topic } Senior Data Researcher\n",
            "goal : >\n",
            "Uncover cutting - edge developments in { topic }\n",
            "backstory : >\n",
            "You're a seasoned researcher with a knack for uncovering the latest\n",
            "developments in { topic } . Known for your ability to find the most relevant\n",
            "information and present it in a clear and concise manner.\n",
            "reporting_analyst :\n",
            "role : >\n",
            "{ topic } Reporting Analyst\n",
            "goal : >\n",
            "Create detailed reports based on { topic } data analysis and research findings\n",
            "backstory : >\n",
            "You're a meticulous analyst with a keen eye for detail. You're known for\n",
            "your ability to turn complex data into clear and concise reports , making\n",
            "it easy for others to understand and act on the information you provide.\n",
            "3 Modify your `tasks.yaml` file tasks.yaml # src/latest_ai_development/config/tasks.yaml\n",
            "research_task :\n",
            "description : >\n",
            "Conduct a thorough research about { topic }\n",
            "Make sure you find any interesting and relevant information given\n",
            "the current year is 2024.\n",
            "expected_output : >\n",
            "A list with 10 bullet points of the most relevant information about { topic }\n",
            "agent : researcher\n",
            "reporting_task :\n",
            "description : >\n",
            "Review the context you got and expand each topic into a full section for a report.\n",
            "Make sure the report is detailed and contains any and all relevant information.\n",
            "expected_output : >\n",
            "A fully fledge reports with the mains topics , each with a full section of information.\n",
            "Formatted as markdown without '```'\n",
            "agent : reporting_analyst\n",
            "output_file : report.md\n",
            "4 Modify your `crew.py` file crew.py # src/latest_ai_development/crew.py\n",
            "from crewai import Agent , Crew , Process , Task\n",
            "from crewai . project import CrewBase , agent , crew , task\n",
            "from crewai_tools import SerperDevTool\n",
            "@CrewBase\n",
            "class LatestAiDevelopmentCrew ( ) :\n",
            "\"\"\"LatestAiDevelopment crew\"\"\"\n",
            "@agent\n",
            "def researcher ( self ) - > Agent :\n",
            "return Agent (\n",
            "config = self . agents_config [ 'researcher' ] ,\n",
            "verbose = True ,\n",
            "tools = [ SerperDevTool ( ) ]\n",
            ")\n",
            "@agent\n",
            "def reporting_analyst ( self ) - > Agent :\n",
            "return Agent (\n",
            "config = self . agents_config [ 'reporting_analyst' ] ,\n",
            "verbose = True\n",
            ")\n",
            "@task\n",
            "def research_task ( self ) - > Task :\n",
            "return Task (\n",
            "config = self . tasks_config [ 'research_task' ] ,\n",
            ")\n",
            "@task\n",
            "def reporting_task ( self ) - > Task :\n",
            "return Task (\n",
            "config = self . tasks_config [ 'reporting_task' ] ,\n",
            "output_file = 'output/report.md' # This is the file that will be contain the final report.\n",
            ")\n",
            "@crew\n",
            "def crew ( self ) - > Crew :\n",
            "\"\"\"Creates the LatestAiDevelopment crew\"\"\"\n",
            "return Crew (\n",
            "agents = self . agents , # Automatically created by the @agent decorator\n",
            "tasks = self . tasks , # Automatically created by the @task decorator\n",
            "process = Process . sequential ,\n",
            "verbose = True ,\n",
            ")\n",
            "5 [Optional] Add before and after crew functions crew.py # src/latest_ai_development/crew.py\n",
            "from crewai import Agent , Crew , Process , Task\n",
            "from crewai . project import CrewBase , agent , crew , task , before_kickoff , after_kickoff\n",
            "from crewai_tools import SerperDevTool\n",
            "@CrewBase\n",
            "class LatestAiDevelopmentCrew ( ) :\n",
            "\"\"\"LatestAiDevelopment crew\"\"\"\n",
            "@before_kickoff\n",
            "def before_kickoff_function ( self , inputs ) :\n",
            "print ( f\"Before kickoff function with inputs: { inputs } \" )\n",
            "return inputs # You can return the inputs or modify them as needed\n",
            "@after_kickoff\n",
            "def after_kickoff_function ( self , result ) :\n",
            "print ( f\"After kickoff function with result: { result } \" )\n",
            "return result # You can return the result or modify it as needed\n",
            "# ... remaining code\n",
            "6 Feel free to pass custom inputs to your crew For example, you can pass the topic input to your crew to customize the research and reporting. main.py #!/usr/bin/env python\n",
            "# src/latest_ai_development/main.py\n",
            "import sys\n",
            "from latest_ai_development . crew import LatestAiDevelopmentCrew\n",
            "def run ( ) :\n",
            "\"\" \"\n",
            "Run the crew .\n",
            "\"\" \"\n",
            "inputs = {\n",
            "'topic' : 'AI Agents'\n",
            "}\n",
            "LatestAiDevelopmentCrew ( ) . crew ( ) . kickoff ( inputs = inputs )\n",
            "7 Set your environment variables Before running your crew, make sure you have the following keys set as environment variables in your .env file:\n",
            "An OpenAI API key (or other LLM API key): OPENAI_API_KEY=sk-...\n",
            "A Serper.dev API key: SERPER_API_KEY=YOUR_KEY_HERE\n",
            "8 Lock and install the dependencies Lock the dependencies and install them by using the CLI command but first, navigate to your project directory: 9 Run your crew To run your crew, execute the following command in the root of your project: 10 View your final report You should see the output in the console and the report.md file should be created in the root of your project with the final report. Here‚Äôs an example of what the report should look like:\n",
            "‚Äã Note on Consistency in Naming\n",
            "The names you use in your YAML files ( agents.yaml and tasks.yaml ) should match the method names in your Python code.\n",
            "For example, you can reference the agent for specific tasks from tasks.yaml file.\n",
            "This naming consistency allows CrewAI to automatically link your configurations with your code; otherwise, your task won‚Äôt recognize the reference properly.\n",
            "‚Äã Example References\n",
            "Note how we use the same name for the agent in the agents.yaml ( email_summarizer ) file as the method name in the crew.py ( email_summarizer ) file.\n",
            "agents.yaml email_summarizer :\n",
            "role : >\n",
            "Email Summarizer\n",
            "goal : >\n",
            "Summarize emails into a concise and clear summary\n",
            "backstory : >\n",
            "You will create a 5 bullet point summary of the report\n",
            "llm : mixtal_llm\n",
            "Note how we use the same name for the agent in the tasks.yaml ( email_summarizer_task ) file as the method name in the crew.py ( email_summarizer_task ) file.\n",
            "tasks.yaml email_summarizer_task :\n",
            "description : >\n",
            "Summarize the email into a 5 bullet point summary\n",
            "expected_output : >\n",
            "A 5 bullet point summary of the email\n",
            "agent : email_summarizer\n",
            "context :\n",
            "- reporting_task\n",
            "- research_task\n",
            "Use the annotations to properly reference the agent and task in the crew.py file.\n",
            "‚Äã Annotations include:\n",
            "@agent\n",
            "@task\n",
            "@crew\n",
            "@tool\n",
            "@before_kickoff\n",
            "@after_kickoff\n",
            "@callback\n",
            "@output_json\n",
            "@output_pydantic\n",
            "@cache_handler\n",
            "crew.py # ...\n",
            "@agent\n",
            "def email_summarizer ( self ) - > Agent :\n",
            "return Agent (\n",
            "config = self . agents_config [ \"email_summarizer\" ] ,\n",
            ")\n",
            "@task\n",
            "def email_summarizer_task ( self ) - > Task :\n",
            "return Task (\n",
            "config = self . tasks_config [ \"email_summarizer_task\" ] ,\n",
            ")\n",
            "# ...\n",
            "In addition to the sequential process , you can use the hierarchical process ,\n",
            "which automatically assigns a manager to the defined crew to properly coordinate the planning and execution of tasks through delegation and validation of results.\n",
            "You can learn more about the core concepts here .\n",
            "‚Äã Replay Tasks from Latest Crew Kickoff\n",
            "CrewAI now includes a replay feature that allows you to list the tasks from the last run and replay from a specific one. To use this feature, run.\n",
            "crewai replay < task_id >\n",
            "Replace <task_id> with the ID of the task you want to replay.\n",
            "‚Äã Reset Crew Memory\n",
            "If you need to reset the memory of your crew before running it again, you can do so by calling the reset memory feature:\n",
            "crewai reset-memories --all\n",
            "This will clear the crew‚Äôs memory, allowing for a fresh start.\n",
            "‚Äã Deploying Your Project\n",
            "The easiest way to deploy your crew is through CrewAI Enterprise, where you can deploy your crew in a few clicks.\n",
            "Deploy on Enterprise Get started with CrewAI Enterprise and deploy your crew in a production environment with just a few clicks. Join the Community Join our open source community to discuss ideas, share your projects, and connect with other CrewAI developers. Was this page helpful? Yes No Installation Agents website x github linkedin youtube Powered by Mintlify On this page Build your first CrewAI Agent Note on Consistency in Naming Example References Annotations include: Replay Tasks from Latest Crew Kickoff Reset Crew Memory Deploying Your Project\u001b[00m\n",
            "\n",
            "\n",
            "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mSenior Support Representative\u001b[00m\n",
            "\u001b[95m## Final Answer:\u001b[00m \u001b[92m\n",
            "Hello Bhanu,\n",
            "\n",
            "Thank you for reaching out! I'm excited to guide you through the process of setting up multiple agents within CrewAI that can collaborate effectively. Additionally, I'll provide information on how to use memory in agents. Let’s dive right in!\n",
            "\n",
            "### Setting Up Multiple Collaborative Agents\n",
            "\n",
            "In CrewAI, you can create multiple agents to handle different tasks collaboratively. This approach allows each agent to specialize in areas aligned with their goals, which enhances overall productivity and efficiency. Below are the steps to set this up:\n",
            "\n",
            "1. **Create Configuration Files**: To define your agents, you will use YAML files (e.g., `agents.yaml` and `tasks.yaml`).\n",
            "\n",
            "   - **agents.yaml**: This file defines the roles, goals, and backstories for each agent. Here’s an example to illustrate:\n",
            "   ```yaml\n",
            "   researcher:\n",
            "     role: \"Senior Data Researcher\"\n",
            "     goal: \"Uncover cutting-edge developments in AI\"\n",
            "     backstory: \"You are a seasoned researcher with a knack for uncovering the latest developments in AI.\"\n",
            "\n",
            "   reporting_analyst:\n",
            "     role: \"Reporting Analyst\"\n",
            "     goal: \"Create detailed reports based on research findings\"\n",
            "     backstory: \"You are a meticulous analyst known for turning complex data into clear reports.\"\n",
            "   ```\n",
            "\n",
            "   - **tasks.yaml**: This file will specify the tasks each agent will perform.\n",
            "   ```yaml\n",
            "   research_task:\n",
            "     description: \"Conduct thorough research about AI\"\n",
            "     expected_output: \"A list with relevant information about AI\"\n",
            "     agent: researcher\n",
            "\n",
            "   reporting_task:\n",
            "     description: \"Review context and expand into a report\"\n",
            "     expected_output: \"A detailed report formatted as markdown.\"\n",
            "     agent: reporting_analyst\n",
            "   ```\n",
            "\n",
            "2. **Implement the Crew**: In your `crew.py` file, you will define your agents and tasks using decorators provided by CrewAI.\n",
            "   ```python\n",
            "   from crewai import Agent, Crew, Process, Task\n",
            "   from crewai.project import CrewBase, agent, crew, task\n",
            "\n",
            "   @CrewBase\n",
            "   class CollaborativeCrew:\n",
            "       @agent\n",
            "       def researcher(self) -> Agent:\n",
            "           return Agent(config=self.agents_config['researcher'])\n",
            "\n",
            "       @agent\n",
            "       def reporting_analyst(self) -> Agent:\n",
            "           return Agent(config=self.agents_config['reporting_analyst'])\n",
            "\n",
            "       @task\n",
            "       def research_task(self) -> Task:\n",
            "           return Task(config=self.tasks_config['research_task'])\n",
            "\n",
            "       @task\n",
            "       def reporting_task(self) -> Task:\n",
            "           return Task(config=self.tasks_config['reporting_task'])\n",
            "\n",
            "       @crew\n",
            "       def crew(self) -> Crew:\n",
            "           return Crew(agents=self.agents, tasks=self.tasks, process=Process.sequential)\n",
            "   ```\n",
            "\n",
            "3. **Kickoff the Crew**: In your main execution file, you can initialize and kick off your crew:\n",
            "   ```python\n",
            "   inputs = {'topic': 'AI Development'}\n",
            "   CollaborativeCrew().crew().kickoff(inputs=inputs)\n",
            "   ```\n",
            "\n",
            "### Using Memory in Agents\n",
            "\n",
            "To make your agents smarter and help them retain important information across different tasks, CrewAI provides a memory feature. Here’s how you can manage memory for your agents:\n",
            "\n",
            "1. **Resetting Memory**: If you need to clear the memory of your crew, you can use the command:\n",
            "   ```bash\n",
            "   crewai reset-memories --all\n",
            "   ```\n",
            "   This will allow your crew to start fresh and not retain any previously stored information.\n",
            "\n",
            "2. **Storing Memory**: If you want your agents to remember specific pieces of information, you can include memory management within your tasks. When a task is executed, you can store contextual information:\n",
            "\n",
            "   - Example:\n",
            "   ```python\n",
            "   @task\n",
            "   def reporting_task(self) -> Task:\n",
            "       # Example code to store memory\n",
            "       current_memory = self.get_memory()  # Retrieve current memory\n",
            "       current_memory['last_topic'] = 'AI Development'  # Update memory accordingly\n",
            "       self.update_memory(current_memory)  # Save updated memory\n",
            "       return Task(config=self.tasks_config['reporting_task'])\n",
            "   ```\n",
            "\n",
            "By utilizing these strategies, you can effectively set up multiple agents to collaborate and extend their capabilities through memory, enabling smoother and richer interactions over time.\n",
            "\n",
            "If you have any further questions or need additional assistance, please don’t hesitate to reach out. I’m here to help!\n",
            "\n",
            "Best regards,  \n",
            "[Your Name]  \n",
            "Senior Support Representative  \n",
            "CrewAI\u001b[00m\n",
            "\n",
            "\n",
            "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mSupport Quality Assurance Specialist\u001b[00m\n",
            "\u001b[95m## Task:\u001b[00m \u001b[92mReview the response drafted by the Senior Support Representative for Maersk's inquiry. Ensure that the answer is comprehensive, accurate, and adheres to the high-quality standards expected for customer support.\n",
            "Verify that all parts of the customer's inquiry have been addressed thoroughly, with a helpful and friendly tone.\n",
            "Check for references and sources used to  find the information, ensuring the response is well-supported and leaves no questions unanswered.\u001b[00m\n",
            "\n",
            "\n",
            "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mSupport Quality Assurance Specialist\u001b[00m\n",
            "\u001b[95m## Final Answer:\u001b[00m \u001b[92m\n",
            "Hello Bhanu,\n",
            "\n",
            "Thank you for reaching out! I'm excited to guide you through the process of setting up multiple agents within CrewAI that can collaborate effectively. Additionally, I'll provide information on how to use memory in agents. Let’s dive right in!\n",
            "\n",
            "### Setting Up Multiple Collaborative Agents\n",
            "\n",
            "In CrewAI, you can create multiple agents to handle different tasks collaboratively. This approach allows each agent to specialize in areas aligned with their goals, enhancing overall productivity and efficiency. Below are the steps to set this up:\n",
            "\n",
            "1. **Create Configuration Files**: To define your agents, you will use YAML files (e.g., `agents.yaml` and `tasks.yaml`).\n",
            "\n",
            "   - **agents.yaml**: This file defines the roles, goals, and backstories for each agent. Here’s an example to illustrate:\n",
            "   ```yaml\n",
            "   researcher:\n",
            "     role: \"Senior Data Researcher\"\n",
            "     goal: \"Uncover cutting-edge developments in AI\"\n",
            "     backstory: \"You are a seasoned researcher with a knack for uncovering the latest developments in AI.\"\n",
            "\n",
            "   reporting_analyst:\n",
            "     role: \"Reporting Analyst\"\n",
            "     goal: \"Create detailed reports based on research findings\"\n",
            "     backstory: \"You are a meticulous analyst known for turning complex data into clear reports.\"\n",
            "   ```\n",
            "\n",
            "   - **tasks.yaml**: This file specifies the tasks each agent will perform.\n",
            "   ```yaml\n",
            "   research_task:\n",
            "     description: \"Conduct thorough research about AI\"\n",
            "     expected_output: \"A list with relevant information about AI\"\n",
            "     agent: researcher\n",
            "\n",
            "   reporting_task:\n",
            "     description: \"Review context and expand into a report\"\n",
            "     expected_output: \"A detailed report formatted as markdown.\"\n",
            "     agent: reporting_analyst\n",
            "   ```\n",
            "\n",
            "2. **Implement the Crew**: In your `crew.py` file, you will define your agents and tasks using decorators provided by CrewAI.\n",
            "   ```python\n",
            "   from crewai import Agent, Crew, Process, Task\n",
            "   from crewai.project import CrewBase, agent, crew, task\n",
            "\n",
            "   @CrewBase\n",
            "   class CollaborativeCrew:\n",
            "       @agent\n",
            "       def researcher(self) -> Agent:\n",
            "           return Agent(config=self.agents_config['researcher'])\n",
            "\n",
            "       @agent\n",
            "       def reporting_analyst(self) -> Agent:\n",
            "           return Agent(config=self.agents_config['reporting_analyst'])\n",
            "\n",
            "       @task\n",
            "       def research_task(self) -> Task:\n",
            "           return Task(config=self.tasks_config['research_task'])\n",
            "\n",
            "       @task\n",
            "       def reporting_task(self) -> Task:\n",
            "           return Task(config=self.tasks_config['reporting_task'])\n",
            "\n",
            "       @crew\n",
            "       def crew(self) -> Crew:\n",
            "           return Crew(agents=self.agents, tasks=self.tasks, process=Process.sequential)\n",
            "   ```\n",
            "\n",
            "3. **Kickoff the Crew**: In your main execution file, you can initialize and kick off your crew:\n",
            "   ```python\n",
            "   inputs = {'topic': 'AI Development'}\n",
            "   CollaborativeCrew().crew().kickoff(inputs=inputs)\n",
            "   ```\n",
            "\n",
            "### Using Memory in Agents\n",
            "\n",
            "To make your agents smarter and help them retain important information across different tasks, CrewAI provides a memory feature. Here’s how you can manage memory for your agents:\n",
            "\n",
            "1. **Resetting Memory**: If you need to clear the memory of your crew, you can use the command:\n",
            "   ```bash\n",
            "   crewai reset-memories --all\n",
            "   ```\n",
            "   This will allow your crew to start fresh and not retain any previously stored information.\n",
            "\n",
            "2. **Storing Memory**: If you want your agents to remember specific pieces of information, you can include memory management within your tasks. When a task is executed, you can store contextual information:\n",
            "\n",
            "   - Example:\n",
            "   ```python\n",
            "   @task\n",
            "   def reporting_task(self) -> Task:\n",
            "       # Example code to store memory\n",
            "       current_memory = self.get_memory()  # Retrieve current memory\n",
            "       current_memory['last_topic'] = 'AI Development'  # Update memory accordingly\n",
            "       self.update_memory(current_memory)  # Save updated memory\n",
            "       return Task(config=self.tasks_config['reporting_task'])\n",
            "   ```\n",
            "\n",
            "By utilizing these strategies, you can effectively set up multiple agents to collaborate and extend their capabilities through memory, enabling smoother and richer interactions over time.\n",
            "\n",
            "If you have any further questions or need additional assistance, please don’t hesitate to reach out. I’m here to help!\n",
            "\n",
            "Best regards,  \n",
            "[Your Name]  \n",
            "Senior Support Representative  \n",
            "CrewAI\u001b[00m\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZbgKlxoNslum"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VyLpHB7JsY4U"
      },
      "execution_count": 36,
      "outputs": []
    }
  ]
}